PS C:\Users\mauro> docker logs -f d63678bedb8c2a60


# Set environment values if they exist as arguments
if [ $# -ne 0 ]; then
  echo "===> Overriding env params with args ..."
  for var in "$@"
  do
    export "$var"
  done
fi
+ '[' 0 -ne 0 ']'

echo "===> ENV Variables ..."
+ echo '===> ENV Variables ...'
env | sort
===> ENV Variables ...
+ env
+ sort
ALLOW_UNSIGNED=false
COMPONENT=kafka
CONFLUENT_DEB_VERSION=1
CONFLUENT_MAJOR_VERSION=5
CONFLUENT_MINOR_VERSION=0
CONFLUENT_MVN_LABEL=
CONFLUENT_PATCH_VERSION=4
CONFLUENT_PLATFORM_LABEL=
CONFLUENT_VERSION=5.0.4
CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
HOME=/root
HOSTNAME=kafka-broker-1
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092
KAFKA_BROKER_ID=1
KAFKA_COMPRESSION_TYPE=producer
KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT
KAFKA_VERSION=2.0.1cp8
KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
LANG=C.UTF-8
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/
PYTHON_PIP_VERSION=8.1.2
PYTHON_VERSION=2.7.9-1
SCALA_VERSION=2.11
SHLVL=1
ZULU_OPENJDK_VERSION=8=8.30.0.1
_=/usr/bin/env
===> User

echo "===> User"
+ echo '===> User'
id
+ id
uid=0(root) gid=0(root) groups=0(root)

echo "===> Configuring ..."
+ echo '===> Configuring ...'
/etc/confluent/docker/configure
===> Configuring ...
+ /etc/confluent/docker/configure

dub ensure KAFKA_ZOOKEEPER_CONNECT
+ dub ensure KAFKA_ZOOKEEPER_CONNECT
dub ensure KAFKA_ADVERTISED_LISTENERS
+ dub ensure KAFKA_ADVERTISED_LISTENERS

# By default, LISTENERS is derived from ADVERTISED_LISTENERS by replacing
# hosts with 0.0.0.0. This is good default as it ensures that the broker
# process listens on all ports.
if [[ -z "${KAFKA_LISTENERS-}" ]]
then
  export KAFKA_LISTENERS
  KAFKA_LISTENERS=$(cub listeners "$KAFKA_ADVERTISED_LISTENERS")
fi
+ [[ -z '' ]]
+ export KAFKA_LISTENERS
cub listeners "$KAFKA_ADVERTISED_LISTENERS"
++ cub listeners PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092
+ KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,LISTENER_LOCAL://0.0.0.0:19092

dub path /etc/kafka/ writable
+ dub path /etc/kafka/ writable

if [[ -z "${KAFKA_LOG_DIRS-}" ]]
then
  export KAFKA_LOG_DIRS
  KAFKA_LOG_DIRS="/var/lib/kafka/data"
fi
+ [[ -z '' ]]
+ export KAFKA_LOG_DIRS
+ KAFKA_LOG_DIRS=/var/lib/kafka/data

# advertised.host, advertised.port, host and port are deprecated. Exit if these properties are set.
if [[ -n "${KAFKA_ADVERTISED_PORT-}" ]]
then
  echo "advertised.port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
  exit 1
fi
+ [[ -n '' ]]

if [[ -n "${KAFKA_ADVERTISED_HOST-}" ]]
then
  echo "advertised.host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
  exit 1
fi
+ [[ -n '' ]]

if [[ -n "${KAFKA_HOST-}" ]]
then
  echo "host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
  exit 1
fi
+ [[ -n '' ]]

if [[ -n "${KAFKA_PORT-}" ]]
then
  echo "port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
  exit 1
fi
+ [[ -n '' ]]

# Set if ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
if [[ $KAFKA_ADVERTISED_LISTENERS == *"SSL://"* ]]
then
  echo "SSL is enabled."

  dub ensure KAFKA_SSL_KEYSTORE_FILENAME
  export KAFKA_SSL_KEYSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_FILENAME"
  dub path "$KAFKA_SSL_KEYSTORE_LOCATION" exists

  dub ensure KAFKA_SSL_KEY_CREDENTIALS
  KAFKA_SSL_KEY_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEY_CREDENTIALS"
  dub path "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION" exists
  export KAFKA_SSL_KEY_PASSWORD
  KAFKA_SSL_KEY_PASSWORD=$(cat "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION")

  dub ensure KAFKA_SSL_KEYSTORE_CREDENTIALS
  KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_CREDENTIALS"
  dub path "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION" exists
  export KAFKA_SSL_KEYSTORE_PASSWORD
  KAFKA_SSL_KEYSTORE_PASSWORD=$(cat "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION")

  if [[ -n "${KAFKA_SSL_CLIENT_AUTH-}" ]] && ( [[ $KAFKA_SSL_CLIENT_AUTH == *"required"* ]] || [[ $KAFKA_SSL_CLIENT_AUTH == *"requested"* ]] )
  then
      dub ensure KAFKA_SSL_TRUSTSTORE_FILENAME
      export KAFKA_SSL_TRUSTSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_FILENAME"
      dub path "$KAFKA_SSL_TRUSTSTORE_LOCATION" exists

      dub ensure KAFKA_SSL_TRUSTSTORE_CREDENTIALS
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_CREDENTIALS"
      dub path "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION" exists
      export KAFKA_SSL_TRUSTSTORE_PASSWORD
      KAFKA_SSL_TRUSTSTORE_PASSWORD=$(cat "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION")
  fi

fi
+ [[ PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092 == *\S\S\L\:\/\/* ]]

# Set if KAFKA_ADVERTISED_LISTENERS has SASL_PLAINTEXT:// or SASL_SSL:// endpoints.
if [[ $KAFKA_ADVERTISED_LISTENERS =~ .*SASL_.*://.* ]]
then
  echo "SASL" is enabled.

  dub ensure KAFKA_OPTS

  if [[ ! $KAFKA_OPTS == *"java.security.auth.login.config"*  ]]
  then
    echo "KAFKA_OPTS should contain 'java.security.auth.login.config' property."
  fi
fi
+ [[ PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092 =~ .*SASL_.*://.* ]]

if [[ -n "${KAFKA_JMX_OPTS-}" ]]
then
  if [[ ! $KAFKA_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
  then
    echo "KAFKA_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
  fi
fi
+ [[ -n '' ]]

dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
+ dub template /etc/confluent/docker/kafka.properties.template /etc/kafka/kafka.properties
dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
+ dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/log4j.properties
dub template "/etc/confluent/docker/tools-log4j.properties.template" "/etc/${COMPONENT}/tools-log4j.properties"
+ dub template /etc/confluent/docker/tools-log4j.properties.template /etc/kafka/tools-log4j.properties

echo "===> Running preflight checks ... "
+ echo '===> Running preflight checks ... '
/etc/confluent/docker/ensure
+ /etc/confluent/docker/ensure
===> Running preflight checks ...

export KAFKA_DATA_DIRS=${KAFKA_DATA_DIRS:-"/var/lib/kafka/data"}
+ export KAFKA_DATA_DIRS=/var/lib/kafka/data
+ KAFKA_DATA_DIRS=/var/lib/kafka/data
===> Check if /var/lib/kafka/data is writable ...
echo "===> Check if $KAFKA_DATA_DIRS is writable ..."
+ echo '===> Check if /var/lib/kafka/data is writable ...'
dub path "$KAFKA_DATA_DIRS" writable
+ dub path /var/lib/kafka/data writable

===> Check if Zookeeper is healthy ...
echo "===> Check if Zookeeper is healthy ..."
+ echo '===> Check if Zookeeper is healthy ...'
cub zk-ready "$KAFKA_ZOOKEEPER_CONNECT" "${KAFKA_CUB_ZK_TIMEOUT:-40}"
+ cub zk-ready zookeeper:2181 40
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=kafka-broker-1
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_172
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Azul Systems, Inc.
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=5.10.16.3-microsoft-standard-WSL2
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
[main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/
[main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@b1bc7ed
[main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to zookeeper/172.18.0.2:2181, initiating session
[main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100000f9aa10000, negotiated timeout = 40000
[main] INFO org.apache.zookeeper.ZooKeeper - Session: 0x100000f9aa10000 closed
===> Launching ...

echo "===> Launching ... "
+ echo '===> Launching ... '
exec /etc/confluent/docker/launch
+ exec /etc/confluent/docker/launch
===> Launching kafka ...
[2022-07-11 15:45:53,286] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-07-11 15:45:53,852] INFO KafkaConfig values:
        advertised.host.name = null
        advertised.listeners = PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092
        advertised.port = null
        alter.config.policy.class.name = null
        alter.log.dirs.replication.quota.window.num = 11
        alter.log.dirs.replication.quota.window.size.seconds = 1
        authorizer.class.name =
        auto.create.topics.enable = true
        auto.leader.rebalance.enable = true
        background.threads = 10
        broker.id = 1
        broker.id.generation.enable = true
        broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
        broker.rack = null
        client.quota.callback.class = null
        compression.type = producer
        connections.max.idle.ms = 600000
        controlled.shutdown.enable = true
        controlled.shutdown.max.retries = 3
        controlled.shutdown.retry.backoff.ms = 5000
        controller.socket.timeout.ms = 30000
        create.topic.policy.class.name = null
        default.replication.factor = 1
        delegation.token.expiry.check.interval.ms = 3600000
        delegation.token.expiry.time.ms = 86400000
        delegation.token.master.key = null
        delegation.token.max.lifetime.ms = 604800000
        delete.records.purgatory.purge.interval.requests = 1
        delete.topic.enable = true
        fetch.purgatory.purge.interval.requests = 1000
        group.initial.rebalance.delay.ms = 3000
        group.max.session.timeout.ms = 300000
        group.min.session.timeout.ms = 6000
        host.name =
        inter.broker.listener.name = PLAINTEXT
        inter.broker.protocol.version = 2.0-IV1
        leader.imbalance.check.interval.seconds = 300
        leader.imbalance.per.broker.percentage = 10
        listener.security.protocol.map = PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT
        listeners = PLAINTEXT://0.0.0.0:9092,LISTENER_LOCAL://0.0.0.0:19092
        log.cleaner.backoff.ms = 15000
        log.cleaner.dedupe.buffer.size = 134217728
        log.cleaner.delete.retention.ms = 86400000
        log.cleaner.enable = true
        log.cleaner.io.buffer.load.factor = 0.9
        log.cleaner.io.buffer.size = 524288
        log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
        log.cleaner.min.cleanable.ratio = 0.5
        log.cleaner.min.compaction.lag.ms = 0
        log.cleaner.threads = 1
        log.cleanup.policy = [delete]
        log.dir = /tmp/kafka-logs
        log.dirs = /var/lib/kafka/data
        log.flush.interval.messages = 9223372036854775807
        log.flush.interval.ms = null
        log.flush.offset.checkpoint.interval.ms = 60000
        log.flush.scheduler.interval.ms = 9223372036854775807
        log.flush.start.offset.checkpoint.interval.ms = 60000
        log.index.interval.bytes = 4096
        log.index.size.max.bytes = 10485760
        log.message.downconversion.enable = true
        log.message.format.version = 2.0-IV1
        log.message.timestamp.difference.max.ms = 9223372036854775807
        log.message.timestamp.type = CreateTime
        log.preallocate = false
        log.retention.bytes = -1
        log.retention.check.interval.ms = 300000
        log.retention.hours = 168
        log.retention.minutes = null
        log.retention.ms = null
        log.roll.hours = 168
        log.roll.jitter.hours = 0
        log.roll.jitter.ms = null
        log.roll.ms = null
        log.segment.bytes = 1073741824
        log.segment.delete.delay.ms = 60000
        max.connections.per.ip = 2147483647
        max.connections.per.ip.overrides =
        max.incremental.fetch.session.cache.slots = 1000
        message.max.bytes = 1000012
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        min.insync.replicas = 1
        num.io.threads = 8
        num.network.threads = 3
        num.partitions = 1
        num.recovery.threads.per.data.dir = 1
        num.replica.alter.log.dirs.threads = null
        num.replica.fetchers = 1
        offset.metadata.max.bytes = 4096
        offsets.commit.required.acks = -1
        offsets.commit.timeout.ms = 5000
        offsets.load.buffer.size = 5242880
        offsets.retention.check.interval.ms = 600000
        offsets.retention.minutes = 10080
        offsets.topic.compression.codec = 0
        offsets.topic.num.partitions = 50
        offsets.topic.replication.factor = 3
        offsets.topic.segment.bytes = 104857600
        password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
        password.encoder.iterations = 4096
        password.encoder.key.length = 128
        password.encoder.keyfactory.algorithm = null
        password.encoder.old.secret = null
        password.encoder.secret = null
        port = 9092
        principal.builder.class = null
        producer.purgatory.purge.interval.requests = 1000
        queued.max.request.bytes = -1
        queued.max.requests = 500
        quota.consumer.default = 9223372036854775807
        quota.producer.default = 9223372036854775807
        quota.window.num = 11
        quota.window.size.seconds = 1
        replica.fetch.backoff.ms = 1000
        replica.fetch.max.bytes = 1048576
        replica.fetch.min.bytes = 1
        replica.fetch.response.max.bytes = 10485760
        replica.fetch.wait.max.ms = 500
        replica.high.watermark.checkpoint.interval.ms = 5000
        replica.lag.time.max.ms = 10000
        replica.socket.receive.buffer.bytes = 65536
        replica.socket.timeout.ms = 30000
        replication.quota.window.num = 11
        replication.quota.window.size.seconds = 1
        request.timeout.ms = 30000
        reserved.broker.max.id = 1000
        sasl.client.callback.handler.class = null
        sasl.enabled.mechanisms = [GSSAPI]
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.principal.to.local.rules = [DEFAULT]
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.mechanism.inter.broker.protocol = GSSAPI
        sasl.server.callback.handler.class = null
        security.inter.broker.protocol = PLAINTEXT
        socket.receive.buffer.bytes = 102400
        socket.request.max.bytes = 104857600
        socket.send.buffer.bytes = 102400
        ssl.cipher.suites = []
        ssl.client.auth = none
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = https
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLS
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
        transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
        transaction.max.timeout.ms = 900000
        transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
        transaction.state.log.load.buffer.size = 5242880
        transaction.state.log.min.isr = 2
        transaction.state.log.num.partitions = 50
        transaction.state.log.replication.factor = 3
        transaction.state.log.segment.bytes = 104857600
        transactional.id.expiration.ms = 604800000
        unclean.leader.election.enable = false
        zookeeper.connect = zookeeper:2181
        zookeeper.connection.timeout.ms = null
        zookeeper.max.in.flight.requests = 10
        zookeeper.session.timeout.ms = 6000
        zookeeper.set.acl = false
        zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-07-11 15:45:54,009] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2022-07-11 15:45:54,048] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[2022-07-11 15:45:54,054] INFO starting (kafka.server.KafkaServer)
[2022-07-11 15:45:54,056] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2022-07-11 15:45:54,089] INFO [ZooKeeperClient] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-07-11 15:45:54,110] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,111] INFO Client environment:host.name=kafka-broker-1 (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,111] INFO Client environment:java.version=1.8.0_172 (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,111] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,112] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,112] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/scala-reflect-2.11.12.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/netty-3.10.6.Final.jar:/usr/bin/../share/java/kafka/httpclient-4.5.2.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.10.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.27.jar:/usr/bin/../share/java/kafka/kafka-tools-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.0.4.jar:/usr/bin/../share/java/kafka/connect-transforms-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/connect-runtime-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0-b42.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/jersey-common-2.27.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8-sources.jar:/usr/bin/../share/java/kafka/connect-api-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/javax.inject-2.5.0-b42.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.11-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.25.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/jersey-client-2.27.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.27.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0-b42.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.7.3.jar:/usr/bin/../share/java/kafka/commons-lang3-3.5.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jline-0.9.94.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.27.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/scala-library-2.11.12.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8-test-sources.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/plexus-utils-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8-javadoc.jar:/usr/bin/../share/java/kafka/httpcore-4.4.4.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.27.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.11.v20180605.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/lz4-java-1.4.1.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8-test.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0-b42.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/zkclient-0.10.jar:/usr/bin/../share/java/kafka/common-utils-5.0.4.jar:/usr/bin/../share/java/kafka/connect-json-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.27.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-clients-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.25.jar:/usr/bin/../share/java/kafka/httpmime-4.5.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.0.4.jar:/usr/bin/../share/java/kafka/connect-file-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/scala-logging_2.11-3.9.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-streams-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.13.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-2.0.1-cp8.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0-b42.jar:/usr/bin/../share/java/kafka/kafka_2.11-2.0.1-cp8-scaladoc.jar:/usr/bin/../share/java/kafka/maven-artifact-3.5.3.jar:/usr/bin/../share/java/confluent-support-metrics/*:/usr/share/java/confluent-support-metrics/* (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,112] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:os.version=5.10.16.3-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,113] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,126] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6c6cb480 (org.apache.zookeeper.ZooKeeper)
[2022-07-11 15:45:54,164] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-07-11 15:45:54,165] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-07-11 15:45:54,177] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2022-07-11 15:45:54,201] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100000f9aa10004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2022-07-11 15:45:54,213] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-07-11 15:45:54,941] INFO Cluster ID = Z914652eRqqmax42oipbPw (kafka.server.KafkaServer)
[2022-07-11 15:45:54,961] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-07-11 15:45:55,070] INFO KafkaConfig values:
        advertised.host.name = null
        advertised.listeners = PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092
        advertised.port = null
        alter.config.policy.class.name = null
        alter.log.dirs.replication.quota.window.num = 11
        alter.log.dirs.replication.quota.window.size.seconds = 1
        authorizer.class.name =
        auto.create.topics.enable = true
        auto.leader.rebalance.enable = true
        background.threads = 10
        broker.id = 1
        broker.id.generation.enable = true
        broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
        broker.rack = null
        client.quota.callback.class = null
        compression.type = producer
        connections.max.idle.ms = 600000
        controlled.shutdown.enable = true
        controlled.shutdown.max.retries = 3
        controlled.shutdown.retry.backoff.ms = 5000
        controller.socket.timeout.ms = 30000
        create.topic.policy.class.name = null
        default.replication.factor = 1
        delegation.token.expiry.check.interval.ms = 3600000
        delegation.token.expiry.time.ms = 86400000
        delegation.token.master.key = null
        delegation.token.max.lifetime.ms = 604800000
        delete.records.purgatory.purge.interval.requests = 1
        delete.topic.enable = true
        fetch.purgatory.purge.interval.requests = 1000
        group.initial.rebalance.delay.ms = 3000
        group.max.session.timeout.ms = 300000
        group.min.session.timeout.ms = 6000
        host.name =
        inter.broker.listener.name = PLAINTEXT
        inter.broker.protocol.version = 2.0-IV1
        leader.imbalance.check.interval.seconds = 300
        leader.imbalance.per.broker.percentage = 10
        listener.security.protocol.map = PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT
        listeners = PLAINTEXT://0.0.0.0:9092,LISTENER_LOCAL://0.0.0.0:19092
        log.cleaner.backoff.ms = 15000
        log.cleaner.dedupe.buffer.size = 134217728
        log.cleaner.delete.retention.ms = 86400000
        log.cleaner.enable = true
        log.cleaner.io.buffer.load.factor = 0.9
        log.cleaner.io.buffer.size = 524288
        log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
        log.cleaner.min.cleanable.ratio = 0.5
        log.cleaner.min.compaction.lag.ms = 0
        log.cleaner.threads = 1
        log.cleanup.policy = [delete]
        log.dir = /tmp/kafka-logs
        log.dirs = /var/lib/kafka/data
        log.flush.interval.messages = 9223372036854775807
        log.flush.interval.ms = null
        log.flush.offset.checkpoint.interval.ms = 60000
        log.flush.scheduler.interval.ms = 9223372036854775807
        log.flush.start.offset.checkpoint.interval.ms = 60000
        log.index.interval.bytes = 4096
        log.index.size.max.bytes = 10485760
        log.message.downconversion.enable = true
        log.message.format.version = 2.0-IV1
        log.message.timestamp.difference.max.ms = 9223372036854775807
        log.message.timestamp.type = CreateTime
        log.preallocate = false
        log.retention.bytes = -1
        log.retention.check.interval.ms = 300000
        log.retention.hours = 168
        log.retention.minutes = null
        log.retention.ms = null
        log.roll.hours = 168
        log.roll.jitter.hours = 0
        log.roll.jitter.ms = null
        log.roll.ms = null
        log.segment.bytes = 1073741824
        log.segment.delete.delay.ms = 60000
        max.connections.per.ip = 2147483647
        max.connections.per.ip.overrides =
        max.incremental.fetch.session.cache.slots = 1000
        message.max.bytes = 1000012
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        min.insync.replicas = 1
        num.io.threads = 8
        num.network.threads = 3
        num.partitions = 1
        num.recovery.threads.per.data.dir = 1
        num.replica.alter.log.dirs.threads = null
        num.replica.fetchers = 1
        offset.metadata.max.bytes = 4096
        offsets.commit.required.acks = -1
        offsets.commit.timeout.ms = 5000
        offsets.load.buffer.size = 5242880
        offsets.retention.check.interval.ms = 600000
        offsets.retention.minutes = 10080
        offsets.topic.compression.codec = 0
        offsets.topic.num.partitions = 50
        offsets.topic.replication.factor = 3
        offsets.topic.segment.bytes = 104857600
        password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
        password.encoder.iterations = 4096
        password.encoder.key.length = 128
        password.encoder.keyfactory.algorithm = null
        password.encoder.old.secret = null
        password.encoder.secret = null
        port = 9092
        principal.builder.class = null
        producer.purgatory.purge.interval.requests = 1000
        queued.max.request.bytes = -1
        queued.max.requests = 500
        quota.consumer.default = 9223372036854775807
        quota.producer.default = 9223372036854775807
        quota.window.num = 11
        quota.window.size.seconds = 1
        replica.fetch.backoff.ms = 1000
        replica.fetch.max.bytes = 1048576
        replica.fetch.min.bytes = 1
        replica.fetch.response.max.bytes = 10485760
        replica.fetch.wait.max.ms = 500
        replica.high.watermark.checkpoint.interval.ms = 5000
        replica.lag.time.max.ms = 10000
        replica.socket.receive.buffer.bytes = 65536
        replica.socket.timeout.ms = 30000
        replication.quota.window.num = 11
        replication.quota.window.size.seconds = 1
        request.timeout.ms = 30000
        reserved.broker.max.id = 1000
        sasl.client.callback.handler.class = null
        sasl.enabled.mechanisms = [GSSAPI]
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.principal.to.local.rules = [DEFAULT]
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.mechanism.inter.broker.protocol = GSSAPI
        sasl.server.callback.handler.class = null
        security.inter.broker.protocol = PLAINTEXT
        socket.receive.buffer.bytes = 102400
        socket.request.max.bytes = 104857600
        socket.send.buffer.bytes = 102400
        ssl.cipher.suites = []
        ssl.client.auth = none
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = https
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLS
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
        transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
        transaction.max.timeout.ms = 900000
        transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
        transaction.state.log.load.buffer.size = 5242880
        transaction.state.log.min.isr = 2
        transaction.state.log.num.partitions = 50
        transaction.state.log.replication.factor = 3
        transaction.state.log.segment.bytes = 104857600
        transactional.id.expiration.ms = 604800000
        unclean.leader.election.enable = false
        zookeeper.connect = zookeeper:2181
        zookeeper.connection.timeout.ms = null
        zookeeper.max.in.flight.requests = 10
        zookeeper.session.timeout.ms = 6000
        zookeeper.set.acl = false
        zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-07-11 15:45:55,091] INFO KafkaConfig values:
        advertised.host.name = null
        advertised.listeners = PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://localhost:19092
        advertised.port = null
        alter.config.policy.class.name = null
        alter.log.dirs.replication.quota.window.num = 11
        alter.log.dirs.replication.quota.window.size.seconds = 1
        authorizer.class.name =
        auto.create.topics.enable = true
        auto.leader.rebalance.enable = true
        background.threads = 10
        broker.id = 1
        broker.id.generation.enable = true
        broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
        broker.rack = null
        client.quota.callback.class = null
        compression.type = producer
        connections.max.idle.ms = 600000
        controlled.shutdown.enable = true
        controlled.shutdown.max.retries = 3
        controlled.shutdown.retry.backoff.ms = 5000
        controller.socket.timeout.ms = 30000
        create.topic.policy.class.name = null
        default.replication.factor = 1
        delegation.token.expiry.check.interval.ms = 3600000
        delegation.token.expiry.time.ms = 86400000
        delegation.token.master.key = null
        delegation.token.max.lifetime.ms = 604800000
        delete.records.purgatory.purge.interval.requests = 1
        delete.topic.enable = true
        fetch.purgatory.purge.interval.requests = 1000
        group.initial.rebalance.delay.ms = 3000
        group.max.session.timeout.ms = 300000
        group.min.session.timeout.ms = 6000
        host.name =
        inter.broker.listener.name = PLAINTEXT
        inter.broker.protocol.version = 2.0-IV1
        leader.imbalance.check.interval.seconds = 300
        leader.imbalance.per.broker.percentage = 10
        listener.security.protocol.map = PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT
        listeners = PLAINTEXT://0.0.0.0:9092,LISTENER_LOCAL://0.0.0.0:19092
        log.cleaner.backoff.ms = 15000
        log.cleaner.dedupe.buffer.size = 134217728
        log.cleaner.delete.retention.ms = 86400000
        log.cleaner.enable = true
        log.cleaner.io.buffer.load.factor = 0.9
        log.cleaner.io.buffer.size = 524288
        log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
        log.cleaner.min.cleanable.ratio = 0.5
        log.cleaner.min.compaction.lag.ms = 0
        log.cleaner.threads = 1
        log.cleanup.policy = [delete]
        log.dir = /tmp/kafka-logs
        log.dirs = /var/lib/kafka/data
        log.flush.interval.messages = 9223372036854775807
        log.flush.interval.ms = null
        log.flush.offset.checkpoint.interval.ms = 60000
        log.flush.scheduler.interval.ms = 9223372036854775807
        log.flush.start.offset.checkpoint.interval.ms = 60000
        log.index.interval.bytes = 4096
        log.index.size.max.bytes = 10485760
        log.message.downconversion.enable = true
        log.message.format.version = 2.0-IV1
        log.message.timestamp.difference.max.ms = 9223372036854775807
        log.message.timestamp.type = CreateTime
        log.preallocate = false
        log.retention.bytes = -1
        log.retention.check.interval.ms = 300000
        log.retention.hours = 168
        log.retention.minutes = null
        log.retention.ms = null
        log.roll.hours = 168
        log.roll.jitter.hours = 0
        log.roll.jitter.ms = null
        log.roll.ms = null
        log.segment.bytes = 1073741824
        log.segment.delete.delay.ms = 60000
        max.connections.per.ip = 2147483647
        max.connections.per.ip.overrides =
        max.incremental.fetch.session.cache.slots = 1000
        message.max.bytes = 1000012
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        min.insync.replicas = 1
        num.io.threads = 8
        num.network.threads = 3
        num.partitions = 1
        num.recovery.threads.per.data.dir = 1
        num.replica.alter.log.dirs.threads = null
        num.replica.fetchers = 1
        offset.metadata.max.bytes = 4096
        offsets.commit.required.acks = -1
        offsets.commit.timeout.ms = 5000
        offsets.load.buffer.size = 5242880
        offsets.retention.check.interval.ms = 600000
        offsets.retention.minutes = 10080
        offsets.topic.compression.codec = 0
        offsets.topic.num.partitions = 50
        offsets.topic.replication.factor = 3
        offsets.topic.segment.bytes = 104857600
        password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
        password.encoder.iterations = 4096
        password.encoder.key.length = 128
        password.encoder.keyfactory.algorithm = null
        password.encoder.old.secret = null
        password.encoder.secret = null
        port = 9092
        principal.builder.class = null
        producer.purgatory.purge.interval.requests = 1000
        queued.max.request.bytes = -1
        queued.max.requests = 500
        quota.consumer.default = 9223372036854775807
        quota.producer.default = 9223372036854775807
        quota.window.num = 11
        quota.window.size.seconds = 1
        replica.fetch.backoff.ms = 1000
        replica.fetch.max.bytes = 1048576
        replica.fetch.min.bytes = 1
        replica.fetch.response.max.bytes = 10485760
        replica.fetch.wait.max.ms = 500
        replica.high.watermark.checkpoint.interval.ms = 5000
        replica.lag.time.max.ms = 10000
        replica.socket.receive.buffer.bytes = 65536
        replica.socket.timeout.ms = 30000
        replication.quota.window.num = 11
        replication.quota.window.size.seconds = 1
        request.timeout.ms = 30000
        reserved.broker.max.id = 1000
        sasl.client.callback.handler.class = null
        sasl.enabled.mechanisms = [GSSAPI]
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.principal.to.local.rules = [DEFAULT]
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.mechanism.inter.broker.protocol = GSSAPI
        sasl.server.callback.handler.class = null
        security.inter.broker.protocol = PLAINTEXT
        socket.receive.buffer.bytes = 102400
        socket.request.max.bytes = 104857600
        socket.send.buffer.bytes = 102400
        ssl.cipher.suites = []
        ssl.client.auth = none
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = https
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLS
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
        transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
        transaction.max.timeout.ms = 900000
        transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
        transaction.state.log.load.buffer.size = 5242880
        transaction.state.log.min.isr = 2
        transaction.state.log.num.partitions = 50
        transaction.state.log.replication.factor = 3
        transaction.state.log.segment.bytes = 104857600
        transactional.id.expiration.ms = 604800000
        unclean.leader.election.enable = false
        zookeeper.connect = zookeeper:2181
        zookeeper.connection.timeout.ms = null
        zookeeper.max.in.flight.requests = 10
        zookeeper.session.timeout.ms = 6000
        zookeeper.set.acl = false
        zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-07-11 15:45:55,174] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-07-11 15:45:55,175] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-07-11 15:45:55,181] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-07-11 15:45:55,260] INFO Loading logs. (kafka.log.LogManager)
[2022-07-11 15:45:55,290] INFO Logs loading complete in 30 ms. (kafka.log.LogManager)
[2022-07-11 15:45:55,318] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-07-11 15:45:55,322] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-07-11 15:45:55,328] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2022-07-11 15:45:55,494] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
[2022-07-11 15:45:56,041] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-07-11 15:45:56,107] INFO Awaiting socket connections on 0.0.0.0:19092. (kafka.network.Acceptor)
[2022-07-11 15:45:56,138] INFO [SocketServer brokerId=1] Started 2 acceptor threads (kafka.network.SocketServer)
[2022-07-11 15:45:56,576] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:56,577] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:56,578] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:56,619] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-07-11 15:45:56,705] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-07-11 15:45:56,721] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2022-07-11 15:45:56,723] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka-broker-1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(localhost,19092,ListenerName(LISTENER_LOCAL),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2022-07-11 15:45:56,726] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-07-11 15:45:57,010] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[2022-07-11 15:45:57,029] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:57,038] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-07-11 15:45:57,045] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:57,051] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-07-11 15:45:57,064] ERROR Error while creating ephemeral at /controller, node already exists and owner '72057661056679942' does not match current session '72057661056679940' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-07-11 15:45:57,064] INFO Result of znode creation at /controller is: NODEEXISTS (kafka.zk.KafkaZkClient)
[2022-07-11 15:45:57,104] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-07-11 15:45:57,107] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-07-11 15:45:57,125] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2022-07-11 15:45:57,163] DEBUG [Controller id=1] Broker 3 was elected as controller instead of broker 1 (kafka.controller.KafkaController)
[2022-07-11 15:45:57,213] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2022-07-11 15:45:57,262] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-07-11 15:45:57,272] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-07-11 15:45:57,275] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-07-11 15:45:57,345] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-07-11 15:45:57,383] INFO [SocketServer brokerId=1] Started processors for 2 acceptors (kafka.network.SocketServer)
[2022-07-11 15:45:57,393] INFO Kafka version : 2.0.1-cp8 (org.apache.kafka.common.utils.AppInfoParser)
[2022-07-11 15:45:57,393] INFO Kafka commitId : 8986da9721fcc857 (org.apache.kafka.common.utils.AppInfoParser)
[2022-07-11 15:45:57,396] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-07-11 15:45:57,401] INFO Waiting until monitored service is ready for metrics collection (io.confluent.support.metrics.BaseMetricsReporter)
[2022-07-11 15:45:57,404] INFO Monitored service is now ready (io.confluent.support.metrics.BaseMetricsReporter)
[2022-07-11 15:45:57,408] INFO Attempting to collect and submit metrics (io.confluent.support.metrics.BaseMetricsReporter)
[2022-07-11 15:45:58,550] INFO Attempting to create topic __confluent.support.metrics with 3 replicas, assuming 3 total brokers (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[2022-07-11 15:45:58,691] INFO Topic creation Map(__confluent.support.metrics-0 -> ArrayBuffer(2, 1, 3)) (kafka.zk.AdminZkClient)
[2022-07-11 15:45:58,710] INFO Topic __confluent.support.metrics already exists (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[2022-07-11 15:45:58,872] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=3,2,1, zkVersion=0, replicas=3,2,1, isNew=true) correlation id 1 from controller 3 epoch 1 for partition __confluent.support.metrics-0 (state.change.logger)
[2022-07-11 15:45:58,881] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 3 epoch 1 starting the become-follower transition for partition __confluent.support.metrics-0 with leader 3 (state.change.logger)
[2022-07-11 15:45:58,937] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:45:59,026] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:45:59,364] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-07-11 15:45:59,383] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 205 ms (kafka.log.Log)
[2022-07-11 15:45:59,388] INFO Created log for partition __confluent.support.metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 31536000000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2022-07-11 15:45:59,403] INFO [Partition __confluent.support.metrics-0 broker=1] No checkpointed highwatermark is found for partition __confluent.support.metrics-0 (kafka.cluster.Partition)
[2022-07-11 15:45:59,404] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:45:59,409] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __confluent.support.metrics-0 (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:45:59,421] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 3 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 with leader 3 (state.change.logger)
[2022-07-11 15:45:59,427] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __confluent.support.metrics-0 as part of become-follower request with correlation id 1 from controller 3 epoch 1 with leader 3 (state.change.logger)
[2022-07-11 15:45:59,523] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:45:59,592] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([__confluent.support.metrics-0, initOffset 0 to broker BrokerEndPoint(3,kafka-broker-3,9092)] ) (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:45:59,620] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 3 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 with leader 3 (state.change.logger)
[2022-07-11 15:45:59,623] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 3 epoch 1 for the become-follower transition for partition __confluent.support.metrics-0 with leader 3 (state.change.logger)
[2022-07-11 15:45:59,634] INFO [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaAlterLogDirsManager)
[2022-07-11 15:45:59,652] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in __confluent.support.metrics-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:45:59,663] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-07-11 15:45:59,686] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=[3, 2, 1], zkVersion=0, replicas=[3, 2, 1], offlineReplicas=[]) for partition __confluent.support.metrics-0 in response to UpdateMetadata request sent by controller 3 epoch 1 with correlation id 2 (state.change.logger)
[2022-07-11 15:46:02,517] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=3,2,1, zkVersion=0, replicas=3,2,1, isNew=true) correlation id 3 from controller 3 epoch 1 for partition _schemas-0 (state.change.logger)
[2022-07-11 15:46:02,520] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 3 epoch 1 starting the become-follower transition for partition _schemas-0 with leader 3 (state.change.logger)
[2022-07-11 15:46:02,521] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:46:02,522] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:46:02,545] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-07-11 15:46:02,548] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2022-07-11 15:46:02,552] INFO Created log for partition _schemas-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2022-07-11 15:46:02,555] INFO [Partition _schemas-0 broker=1] No checkpointed highwatermark is found for partition _schemas-0 (kafka.cluster.Partition)
[2022-07-11 15:46:02,556] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:46:02,557] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _schemas-0 (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:46:02,562] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 3 epoch 1 with correlation id 3 for partition _schemas-0 with leader 3 (state.change.logger)
[2022-07-11 15:46:02,562] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _schemas-0 as part of become-follower request with correlation id 3 from controller 3 epoch 1 with leader 3 (state.change.logger)
[2022-07-11 15:46:02,564] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([_schemas-0, initOffset 0 to broker BrokerEndPoint(3,kafka-broker-3,9092)] ) (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:46:02,564] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 3 epoch 1 with correlation id 3 for partition _schemas-0 with leader 3 (state.change.logger)
[2022-07-11 15:46:02,564] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 3 epoch 1 for the become-follower transition for partition _schemas-0 with leader 3 (state.change.logger)
[2022-07-11 15:46:02,564] INFO [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaAlterLogDirsManager)
[2022-07-11 15:46:02,574] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=[3, 2, 1], zkVersion=0, replicas=[3, 2, 1], offlineReplicas=[]) for partition _schemas-0 in response to UpdateMetadata request sent by controller 3 epoch 1 with correlation id 4 (state.change.logger)
[2022-07-11 15:46:02,671] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in _schemas-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:46:02,672] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-07-11 15:46:02,712] INFO Successfully submitted metrics to Confluent via secure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[2022-07-11 15:48:37,903] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,3,1, zkVersion=0, replicas=2,3,1, isNew=true) correlation id 5 from controller 3 epoch 1 for partition twitter-topic-0 (state.change.logger)
[2022-07-11 15:48:37,903] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2,3, zkVersion=0, replicas=1,2,3, isNew=true) correlation id 5 from controller 3 epoch 1 for partition twitter-topic-1 (state.change.logger)
[2022-07-11 15:48:37,904] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=3,1,2, zkVersion=0, replicas=3,1,2, isNew=true) correlation id 5 from controller 3 epoch 1 for partition twitter-topic-2 (state.change.logger)
[2022-07-11 15:48:37,918] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 3 epoch 1 starting the become-leader transition for partition twitter-topic-1 (state.change.logger)
[2022-07-11 15:48:37,920] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions twitter-topic-1 (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:48:37,941] INFO [Log partition=twitter-topic-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-07-11 15:48:37,949] INFO [Log partition=twitter-topic-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2022-07-11 15:48:37,952] INFO Created log for partition twitter-topic-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2022-07-11 15:48:37,954] INFO [Partition twitter-topic-1 broker=1] No checkpointed highwatermark is found for partition twitter-topic-1 (kafka.cluster.Partition)
[2022-07-11 15:48:37,954] INFO Replica loaded for partition twitter-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:37,954] INFO Replica loaded for partition twitter-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:37,955] INFO Replica loaded for partition twitter-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:37,957] INFO [Partition twitter-topic-1 broker=1] twitter-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2022-07-11 15:48:37,992] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 3 epoch 1 with correlation id 5 for partition twitter-topic-1 (last update controller epoch 1) (state.change.logger)
[2022-07-11 15:48:37,994] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 3 epoch 1 for the become-leader transition for partition twitter-topic-1 (state.change.logger)
[2022-07-11 15:48:37,994] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 3 epoch 1 starting the become-follower transition for partition twitter-topic-2 with leader 3 (state.change.logger)
[2022-07-11 15:48:37,994] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 3 epoch 1 starting the become-follower transition for partition twitter-topic-0 with leader 2 (state.change.logger)
[2022-07-11 15:48:37,995] INFO Replica loaded for partition twitter-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,003] INFO [Log partition=twitter-topic-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-07-11 15:48:38,004] INFO [Log partition=twitter-topic-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2022-07-11 15:48:38,006] INFO Created log for partition twitter-topic-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2022-07-11 15:48:38,007] INFO [Partition twitter-topic-2 broker=1] No checkpointed highwatermark is found for partition twitter-topic-2 (kafka.cluster.Partition)
[2022-07-11 15:48:38,007] INFO Replica loaded for partition twitter-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,008] INFO Replica loaded for partition twitter-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,008] INFO Replica loaded for partition twitter-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,008] INFO Replica loaded for partition twitter-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,026] INFO [Log partition=twitter-topic-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-07-11 15:48:38,028] INFO [Log partition=twitter-topic-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2022-07-11 15:48:38,039] INFO Created log for partition twitter-topic-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2022-07-11 15:48:38,040] INFO [Partition twitter-topic-0 broker=1] No checkpointed highwatermark is found for partition twitter-topic-0 (kafka.cluster.Partition)
[2022-07-11 15:48:38,041] INFO Replica loaded for partition twitter-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2022-07-11 15:48:38,042] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions twitter-topic-0,twitter-topic-2 (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:48:38,042] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 3 epoch 1 with correlation id 5 for partition twitter-topic-0 with leader 2 (state.change.logger)
[2022-07-11 15:48:38,042] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 3 epoch 1 with correlation id 5 for partition twitter-topic-2 with leader 3 (state.change.logger)
[2022-07-11 15:48:38,042] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition twitter-topic-0 as part of become-follower request with correlation id 5 from controller 3 epoch 1 with leader 2 (state.change.logger)
[2022-07-11 15:48:38,042] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition twitter-topic-2 as part of become-follower request with correlation id 5 from controller 3 epoch 1 with leader 3 (state.change.logger)
[2022-07-11 15:48:38,054] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([twitter-topic-0, initOffset 0 to broker BrokerEndPoint(2,kafka-broker-2,9092)] , [twitter-topic-2, initOffset 0 to broker BrokerEndPoint(3,kafka-broker-3,9092)] ) (kafka.server.ReplicaFetcherManager)
[2022-07-11 15:48:38,055] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 3 epoch 1 with correlation id 5 for partition twitter-topic-0 with leader 2 (state.change.logger)
[2022-07-11 15:48:38,055] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 3 epoch 1 with correlation id 5 for partition twitter-topic-2 with leader 3 (state.change.logger)
[2022-07-11 15:48:38,056] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 3 epoch 1 for the become-follower transition for partition twitter-topic-2 with leader 3 (state.change.logger)
[2022-07-11 15:48:38,057] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 3 epoch 1 for the become-follower transition for partition twitter-topic-0 with leader 2 (state.change.logger)
[2022-07-11 15:48:38,058] INFO [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaAlterLogDirsManager)
[2022-07-11 15:48:38,060] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:48:38,064] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in twitter-topic-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:48:38,064] INFO [Log partition=twitter-topic-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-07-11 15:48:38,080] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 3, 1], zkVersion=0, replicas=[2, 3, 1], offlineReplicas=[]) for partition twitter-topic-0 in response to UpdateMetadata request sent by controller 3 epoch 1 with correlation id 6 (state.change.logger)
[2022-07-11 15:48:38,081] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 3], zkVersion=0, replicas=[1, 2, 3], offlineReplicas=[]) for partition twitter-topic-1 in response to UpdateMetadata request sent by controller 3 epoch 1 with correlation id 6 (state.change.logger)
[2022-07-11 15:48:38,081] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=3, leaderEpoch=0, isr=[3, 1, 2], zkVersion=0, replicas=[3, 1, 2], offlineReplicas=[]) for partition twitter-topic-2 in response to UpdateMetadata request sent by controller 3 epoch 1 with correlation id 6 (state.change.logger)
[2022-07-11 15:48:38,143] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition twitter-topic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2022-07-11 15:48:38,552] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in twitter-topic-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2022-07-11 15:48:38,552] INFO [Log partition=twitter-topic-2, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-07-11 15:55:57,105] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2022-07-11 16:05:57,104] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2022-07-11 16:15:57,105] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2022-07-11 16:25:57,105] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2022-07-11 16:35:57,105] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
